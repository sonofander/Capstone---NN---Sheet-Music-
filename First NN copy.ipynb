{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/dcolton/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from keras.utils import np_utils \n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: 'A/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8dcdbdff0c57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     class_mode='binary')\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m validation_generator = test_datagen.flow_from_directory(\n",
      "\u001b[0;32m/Users/dcolton/anaconda/lib/python2.7/site-packages/keras/preprocessing/image.pyc\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             follow_links=follow_links)\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dcolton/anaconda/lib/python2.7/site-packages/keras/preprocessing/image.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: 'A/train'"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 300, 300\n",
    "\n",
    "train_data_dir = 'A/train'\n",
    "validation_data_dir = 'A/test'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = load_img('FluteTunes/A/79th\\'s Farewell to Gibraltar.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = x.reshape((1,) + x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Grayscale = 0.2125R + 0.7154G + 0.0721B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "asdf = ImageDataGenerator(featurewise_center=False, samplewise_center=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input to `.fit()` should have rank 4. Got array with shape: (300, 300, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-3afd2c669108>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/dcolton/anaconda/lib/python2.7/site-packages/keras/preprocessing/image.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, augment, rounds, seed)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             raise ValueError('Input to `.fit()` should have rank 4. '\n\u001b[0;32m--> 635\u001b[0;31m                              'Got array with shape: ' + str(x.shape))\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_axis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Input to `.fit()` should have rank 4. Got array with shape: (300, 300, 3)"
     ]
    }
   ],
   "source": [
    "asdf.fit(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = load_img('FluteTunes/A/79th\\'s Farewell to Gibraltar.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "onlyfiles = [f for f in listdir('/Users/dcolton/Desktop/capstone/FluteTunes/E/') if isfile(join('/Users/dcolton/Desktop/capstone/FluteTunes/E/', f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adagio ma non tanto Sonata No. 6 in E major for flute and continuo-0.png',\n",
       " 'Adagio ma non tanto Sonata No. 6 in E major for flute and continuo-1.png',\n",
       " 'Adagio ma non tanto Sonata No. 6 in E major for flute and continuo-2.png',\n",
       " 'Adagio ma non tanto Sonata No. 6 in E major for flute and continuo.pdf',\n",
       " 'Affettuoso Sonates sans Basse a\\xcc\\x80 deux Flutes traverses, No. 6-0.png',\n",
       " 'Affettuoso Sonates sans Basse a\\xcc\\x80 deux Flutes traverses, No. 6-1.png',\n",
       " 'Affettuoso Sonates sans Basse a\\xcc\\x80 deux Flutes traverses, No. 6.pdf',\n",
       " 'Allegro assai Sonata No. 6 in E major for flute and continuo-0.png',\n",
       " 'Allegro assai Sonata No. 6 in E major for flute and continuo-1.png',\n",
       " 'Allegro assai Sonata No. 6 in E major for flute and continuo-2.png',\n",
       " 'Allegro assai Sonata No. 6 in E major for flute and continuo-3.png',\n",
       " 'Allegro assai Sonata No. 6 in E major for flute and continuo.pdf',\n",
       " 'Allegro Sonata No. 6 in E major for flute and continuo-0.png',\n",
       " 'Allegro Sonata No. 6 in E major for flute and continuo-1.png',\n",
       " 'Allegro Sonata No. 6 in E major for flute and continuo-2.png',\n",
       " 'Allegro Sonata No. 6 in E major for flute and continuo-3.png',\n",
       " 'Allegro Sonata No. 6 in E major for flute and continuo.pdf',\n",
       " 'Andante Flute Trio No. 2-0.png',\n",
       " 'Andante Flute Trio No. 2-1.png',\n",
       " 'Andante Flute Trio No. 2.pdf',\n",
       " 'Andante Six duos faciles et brillants, No. 4.pdf',\n",
       " 'Andante Six duos faciles et brillants, No. 4.png',\n",
       " 'Arabesque No. 1 Two Arabesques-0.png',\n",
       " 'Arabesque No. 1 Two Arabesques-1.png',\n",
       " 'Arabesque No. 1 Two Arabesques-2.png',\n",
       " 'Arabesque No. 1 Two Arabesques-3.png',\n",
       " 'Arabesque No. 1 Two Arabesques-4.png',\n",
       " 'Arabesque No. 1 Two Arabesques-5.png',\n",
       " 'Arabesque No. 1 Two Arabesques-6.png',\n",
       " 'Arabesque No. 1 Two Arabesques-7.png',\n",
       " 'Arabesque No. 1 Two Arabesques.pdf',\n",
       " 'Baby Monkey (Going Backwards On A Pig).pdf',\n",
       " 'Baby Monkey (Going Backwards On A Pig).png',\n",
       " 'Berceuse Dolly-0.png',\n",
       " 'Berceuse Dolly-1.png',\n",
       " 'Berceuse Dolly-2.png',\n",
       " 'Berceuse Dolly-3.png',\n",
       " 'Berceuse Dolly-4.png',\n",
       " 'Berceuse Dolly.pdf',\n",
       " 'Berceuse-0.png',\n",
       " 'Berceuse-1.png',\n",
       " 'Berceuse-2.png',\n",
       " 'Berceuse-3.png',\n",
       " 'Berceuse-4.png',\n",
       " 'Berceuse-5.png',\n",
       " 'Berceuse-6.png',\n",
       " 'Berceuse.pdf',\n",
       " 'Caprice No. 9 in E major 26 Little Caprices.pdf',\n",
       " 'Caprice No. 9 in E major 26 Little Caprices.png',\n",
       " \"Carillon L'Arle\\xcc\\x81sienne Suite No. 1-0.png\",\n",
       " \"Carillon L'Arle\\xcc\\x81sienne Suite No. 1-1.png\",\n",
       " \"Carillon L'Arle\\xcc\\x81sienne Suite No. 1-2.png\",\n",
       " \"Carillon L'Arle\\xcc\\x81sienne Suite No. 1-3.png\",\n",
       " \"Carillon L'Arle\\xcc\\x81sienne Suite No. 1-4.png\",\n",
       " \"Carillon L'Arle\\xcc\\x81sienne Suite No. 1.pdf\",\n",
       " 'Dance of the Hours La Gioconda-0.png',\n",
       " 'Dance of the Hours La Gioconda-1.png',\n",
       " 'Dance of the Hours La Gioconda-2.png',\n",
       " 'Dance of the Hours La Gioconda.pdf',\n",
       " \"Dieu d'amour Les mariages samnites-0.png\",\n",
       " \"Dieu d'amour Les mariages samnites-1.png\",\n",
       " \"Dieu d'amour Les mariages samnites.pdf\",\n",
       " 'Duet No. 11 in E major School of Flute, Grade 2-0.png',\n",
       " 'Duet No. 11 in E major School of Flute, Grade 2-1.png',\n",
       " 'Duet No. 11 in E major School of Flute, Grade 2-2.png',\n",
       " 'Duet No. 11 in E major School of Flute, Grade 2-3.png',\n",
       " 'Duet No. 11 in E major School of Flute, Grade 2.pdf',\n",
       " 'Duet No. 16 in E major School of Flute, Grade 2-0.png',\n",
       " 'Duet No. 16 in E major School of Flute, Grade 2-1.png',\n",
       " 'Duet No. 16 in E major School of Flute, Grade 2-2.png',\n",
       " 'Duet No. 16 in E major School of Flute, Grade 2-3.png',\n",
       " 'Duet No. 16 in E major School of Flute, Grade 2.pdf',\n",
       " 'Fantasia No. 9 in E major 12 Fantasias for Solo Flute-0.png',\n",
       " 'Fantasia No. 9 in E major 12 Fantasias for Solo Flute-1.png',\n",
       " 'Fantasia No. 9 in E major 12 Fantasias for Solo Flute.pdf',\n",
       " 'Holy, Holy, Holy.pdf',\n",
       " 'Holy, Holy, Holy.png',\n",
       " 'Invention No. 6 in E major-0.png',\n",
       " 'Invention No. 6 in E major-1.png',\n",
       " 'Invention No. 6 in E major.pdf',\n",
       " 'La Criarde 55 Easy Pieces.pdf',\n",
       " 'La Criarde 55 Easy Pieces.png',\n",
       " 'Morning Mood Peer Gynt Suite No. 1-0.png',\n",
       " 'Morning Mood Peer Gynt Suite No. 1-1.png',\n",
       " 'Morning Mood Peer Gynt Suite No. 1-2.png',\n",
       " 'Morning Mood Peer Gynt Suite No. 1-3.png',\n",
       " 'Morning Mood Peer Gynt Suite No. 1-4.png',\n",
       " 'Morning Mood Peer Gynt Suite No. 1-5.png',\n",
       " 'Morning Mood Peer Gynt Suite No. 1.pdf',\n",
       " \"Nocturne A Midsummer Night's Dream-0.png\",\n",
       " \"Nocturne A Midsummer Night's Dream-1.png\",\n",
       " \"Nocturne A Midsummer Night's Dream.pdf\",\n",
       " 'Overture William Tell-0.png',\n",
       " 'Overture William Tell-1.png',\n",
       " 'Overture William Tell-2.png',\n",
       " 'Overture William Tell.pdf',\n",
       " 'Preludio La traviata.pdf',\n",
       " 'Preludio La traviata.png',\n",
       " 'Presto Sonates sans Basse a\\xcc\\x80 deux Flutes traverses, No. 6-0.png',\n",
       " 'Presto Sonates sans Basse a\\xcc\\x80 deux Flutes traverses, No. 6-1.png',\n",
       " 'Presto Sonates sans Basse a\\xcc\\x80 deux Flutes traverses, No. 6-2.png',\n",
       " 'Presto Sonates sans Basse a\\xcc\\x80 deux Flutes traverses, No. 6.pdf',\n",
       " 'Pre\\xcc\\x81lude in E major 55 Easy Pieces.pdf',\n",
       " 'Pre\\xcc\\x81lude in E major 55 Easy Pieces.png',\n",
       " \"Quando me'n vo' La bohe\\xcc\\x80me-0.png\",\n",
       " \"Quando me'n vo' La bohe\\xcc\\x80me-1.png\",\n",
       " \"Quando me'n vo' La bohe\\xcc\\x80me-2.png\",\n",
       " \"Quando me'n vo' La bohe\\xcc\\x80me-3.png\",\n",
       " \"Quando me'n vo' La bohe\\xcc\\x80me.pdf\",\n",
       " 'Russian Dance 25 Romantic Studies.pdf',\n",
       " 'Russian Dance 25 Romantic Studies.png',\n",
       " \"Salut d'Amour-0.png\",\n",
       " \"Salut d'Amour-1.png\",\n",
       " \"Salut d'Amour-2.png\",\n",
       " \"Salut d'Amour-3.png\",\n",
       " \"Salut d'Amour.pdf\",\n",
       " 'Serenata-0.png',\n",
       " 'Serenata-1.png',\n",
       " 'Serenata-2.png',\n",
       " 'Serenata-3.png',\n",
       " 'Serenata.pdf',\n",
       " 'Spiritoso Sonates sans Basse a\\xcc\\x80 deux Flutes traverses, No. 6-0.png',\n",
       " 'Spiritoso Sonates sans Basse a\\xcc\\x80 deux Flutes traverses, No. 6-1.png',\n",
       " 'Spiritoso Sonates sans Basse a\\xcc\\x80 deux Flutes traverses, No. 6.pdf',\n",
       " 'Spring The Four Seasons-0.png',\n",
       " 'Spring The Four Seasons-1.png',\n",
       " 'Spring The Four Seasons-2.png',\n",
       " 'Spring The Four Seasons-3.png',\n",
       " 'Spring The Four Seasons-4.png',\n",
       " 'Spring The Four Seasons.pdf',\n",
       " 'Study No. 12 in E major 32 Etudes amusantes et instructives.pdf',\n",
       " 'Study No. 12 in E major 32 Etudes amusantes et instructives.png',\n",
       " 'Study No. 12 in E major 50 Etudes me\\xcc\\x81lodiques.pdf',\n",
       " 'Study No. 12 in E major 50 Etudes me\\xcc\\x81lodiques.png',\n",
       " 'Study No. 14 in E major 18 Exercises or Etudes for Flute-0.png',\n",
       " 'Study No. 14 in E major 18 Exercises or Etudes for Flute-1.png',\n",
       " 'Study No. 14 in E major 18 Exercises or Etudes for Flute.pdf',\n",
       " 'Study No. 14 in E major Twenty Studies.pdf',\n",
       " 'Study No. 14 in E major Twenty Studies.png',\n",
       " 'Study No. 15 in E major 72 Studies for the Boehm Flute.pdf',\n",
       " 'Study No. 15 in E major 72 Studies for the Boehm Flute.png',\n",
       " 'Study No. 15 in E major Me\\xcc\\x81thode pour la flu\\xcc\\x82te.pdf',\n",
       " 'Study No. 15 in E major Me\\xcc\\x81thode pour la flu\\xcc\\x82te.png',\n",
       " 'Study No. 15 in E major Progress in Flute Playing, Book 1.pdf',\n",
       " 'Study No. 15 in E major Progress in Flute Playing, Book 1.png',\n",
       " 'Study No. 15 in E major Vingt e\\xcc\\x81tudes chantantes pour la flu\\xcc\\x82te.pdf',\n",
       " 'Study No. 15 in E major Vingt e\\xcc\\x81tudes chantantes pour la flu\\xcc\\x82te.png',\n",
       " 'Study No. 17 in E major 24 Caprice-Etudes-0.png',\n",
       " 'Study No. 17 in E major 24 Caprice-Etudes-1.png',\n",
       " 'Study No. 17 in E major 24 Caprice-Etudes.pdf',\n",
       " 'Study No. 17 in E major 24 Etudes.pdf',\n",
       " 'Study No. 17 in E major 24 Etudes.png',\n",
       " 'Study No. 17 in E major 50 Etudes me\\xcc\\x81lodiques.pdf',\n",
       " 'Study No. 17 in E major 50 Etudes me\\xcc\\x81lodiques.png',\n",
       " 'Study No. 19 in E major 30 Studies for Flute Solo.pdf',\n",
       " 'Study No. 19 in E major 30 Studies for Flute Solo.png',\n",
       " 'Study No. 19 in E major 50 Etudes me\\xcc\\x81lodiques.pdf',\n",
       " 'Study No. 19 in E major 50 Etudes me\\xcc\\x81lodiques.png',\n",
       " 'Study No. 27 in E major 30 Studies for Flute Solo.pdf',\n",
       " 'Study No. 27 in E major 30 Studies for Flute Solo.png',\n",
       " 'Study No. 30 in E major Thirty Easy and Progressive Studies.pdf',\n",
       " 'Study No. 30 in E major Thirty Easy and Progressive Studies.png',\n",
       " 'Study No. 31 in E major 32 Etudes amusantes et instructives.pdf',\n",
       " 'Study No. 31 in E major 32 Etudes amusantes et instructives.png',\n",
       " 'Study No. 36 in E major 72 Studies for the Boehm Flute.pdf',\n",
       " 'Study No. 36 in E major 72 Studies for the Boehm Flute.png',\n",
       " 'Study No. 42 in E major Me\\xcc\\x81thode pour la flu\\xcc\\x82te.pdf',\n",
       " 'Study No. 42 in E major Me\\xcc\\x81thode pour la flu\\xcc\\x82te.png',\n",
       " 'Study No. 5 in E major 50 Etudes me\\xcc\\x81lodiques.pdf',\n",
       " 'Study No. 5 in E major 50 Etudes me\\xcc\\x81lodiques.png',\n",
       " 'Study No. 57 in E major 72 Studies for the Boehm Flute.pdf',\n",
       " 'Study No. 57 in E major 72 Studies for the Boehm Flute.png',\n",
       " 'Study No. 9 in E major 18 Etudes for Flute.pdf',\n",
       " 'Study No. 9 in E major 18 Etudes for Flute.png',\n",
       " 'Study No. 9 in E major 24 Etudes for Flute, Op. 30-0.png',\n",
       " 'Study No. 9 in E major 24 Etudes for Flute, Op. 30-1.png',\n",
       " 'Study No. 9 in E major 24 Etudes for Flute, Op. 30.pdf',\n",
       " 'Study No. 9 in E major 24 Etudes for Flute, Op. 33.pdf',\n",
       " 'Study No. 9 in E major 24 Etudes for Flute, Op. 33.png',\n",
       " 'Tarentelle 50 Etudes me\\xcc\\x81lodiques.pdf',\n",
       " 'Tarentelle 50 Etudes me\\xcc\\x81lodiques.png',\n",
       " 'The British Grenadiers.pdf',\n",
       " 'The British Grenadiers.png',\n",
       " 'The Cuckoo and the Nightingale 25 Romantic Studies.pdf',\n",
       " 'The Cuckoo and the Nightingale 25 Romantic Studies.png',\n",
       " 'Tristesse-0.png',\n",
       " 'Tristesse-1.png',\n",
       " 'Tristesse.pdf',\n",
       " 'Variations on a Theme by Rossini-0.png',\n",
       " 'Variations on a Theme by Rossini-1.png',\n",
       " 'Variations on a Theme by Rossini-2.png',\n",
       " 'Variations on a Theme by Rossini-3.png',\n",
       " 'Variations on a Theme by Rossini-4.png',\n",
       " 'Variations on a Theme by Rossini-5.png',\n",
       " 'Variations on a Theme by Rossini-6.png',\n",
       " 'Variations on a Theme by Rossini-7.png',\n",
       " 'Variations on a Theme by Rossini.pdf']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KERAS\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import theano\n",
    "from PIL import Image\n",
    "from numpy import *\n",
    "# SKLEARN\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 200, 200\n",
    "\n",
    "# number of channels\n",
    "img_channels = 1\n",
    "\n",
    "#%%\n",
    "#  data\n",
    "\n",
    "path1 = 'C:\\Users\\Ripul\\Documents\\Python Scripts\\keeras-cnn-tutorial\\input_data'    #path of folder of images    \n",
    "path2 = 'C:\\Users\\Ripul\\Documents\\Python Scripts\\keeras-cnn-tutorial\\input_data_resized'  #path of folder to save images    \n",
    "\n",
    "listing = os.listdir(path1) \n",
    "num_samples=size(listing)\n",
    "print num_samples\n",
    "\n",
    "for file in listing:\n",
    "    im = Image.open(path1 + '\\\\' + file)   \n",
    "    img = im.resize((img_rows,img_cols))\n",
    "    gray = img.convert('L')\n",
    "                #need to do some more processing here           \n",
    "    gray.save(path2 +'\\\\' +  file, \"JPEG\")\n",
    "\n",
    "imlist = os.listdir(path2)\n",
    "\n",
    "im1 = array(Image.open('input_data_resized' + '\\\\'+ imlist[0])) # open one image to get size\n",
    "m,n = im1.shape[0:2] # get the size of the images\n",
    "imnbr = len(imlist) # get the number of images\n",
    "\n",
    "# create matrix to store all flattened images\n",
    "immatrix = array([array(Image.open('input_data_resized'+ '\\\\' + im2)).flatten()\n",
    "              for im2 in imlist],'f')\n",
    "                \n",
    "label=np.ones((num_samples,),dtype = int)\n",
    "label[0:89]=0\n",
    "label[89:187]=1\n",
    "label[187:]=2\n",
    "\n",
    "\n",
    "data,Label = shuffle(immatrix,label, random_state=2)\n",
    "train_data = [data,Label]\n",
    "\n",
    "img=immatrix[167].reshape(img_rows,img_cols)\n",
    "plt.imshow(img)\n",
    "plt.imshow(img,cmap='gray')\n",
    "print (train_data[0].shape)\n",
    "print (train_data[1].shape)\n",
    "\n",
    "#%%\n",
    "\n",
    "#batch_size to train\n",
    "batch_size = 32\n",
    "# number of output classes\n",
    "nb_classes = 3\n",
    "# number of epochs to train\n",
    "nb_epoch = 20\n",
    "\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "\n",
    "#%%\n",
    "(X, y) = (train_data[0],train_data[1])\n",
    "\n",
    "\n",
    "# STEP 1: split X and y into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "i = 100\n",
    "plt.imshow(X_train[i, 0], interpolation='nearest')\n",
    "print(\"label : \", Y_train[i,:])\n",
    "\n",
    "#%%\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                        border_mode='valid',\n",
    "                        input_shape=(1, img_rows, img_cols)))\n",
    "convout1 = Activation('relu')\n",
    "model.add(convout1)\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
    "convout2 = Activation('relu')\n",
    "model.add(convout2)\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
    "\n",
    "#%%\n",
    "\n",
    "hist = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "              show_accuracy=True, verbose=1, validation_data=(X_test, Y_test))\n",
    "            \n",
    "            \n",
    "hist = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "              show_accuracy=True, verbose=1, validation_split=0.2)\n",
    "\n",
    "\n",
    "# visualizing losses and accuracy\n",
    "\n",
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['acc']\n",
    "val_acc=hist.history['val_acc']\n",
    "xc=range(nb_epoch)\n",
    "\n",
    "plt.figure(1,figsize=(7,5))\n",
    "plt.plot(xc,train_loss)\n",
    "plt.plot(xc,val_loss)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('train_loss vs val_loss')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'])\n",
    "print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n",
    "\n",
    "plt.figure(2,figsize=(7,5))\n",
    "plt.plot(xc,train_acc)\n",
    "plt.plot(xc,val_acc)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('train_acc vs val_acc')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'],loc=4)\n",
    "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#%%       \n",
    "\n",
    "score = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(model.predict_classes(X_test[1:5]))\n",
    "print(Y_test[1:5])\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "# visualizing intermediate layers\n",
    "\n",
    "output_layer = model.layers[1].get_output()\n",
    "output_fn = theano.function([model.layers[0].get_input()], output_layer)\n",
    "\n",
    "# the input image\n",
    "\n",
    "input_image=X_train[0:1,:,:,:]\n",
    "print(input_image.shape)\n",
    "\n",
    "plt.imshow(input_image[0,0,:,:],cmap ='gray')\n",
    "plt.imshow(input_image[0,0,:,:])\n",
    "\n",
    "\n",
    "output_image = output_fn(input_image)\n",
    "print(output_image.shape)\n",
    "\n",
    "# Rearrange dimension so we can plot the result \n",
    "output_image = np.rollaxis(np.rollaxis(output_image, 3, 1), 3, 1)\n",
    "print(output_image.shape)\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(8,8))\n",
    "for i in range(32):\n",
    "    ax = fig.add_subplot(6, 6, i+1)\n",
    "    #ax.imshow(output_image[0,:,:,i],interpolation='nearest' ) #to see the first filter\n",
    "    ax.imshow(output_image[0,:,:,i],cmap=matplotlib.cm.gray)\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "    plt.tight_layout()\n",
    "plt\n",
    "\n",
    "# Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print(y_pred)\n",
    "  \n",
    "                       (or)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "p=model.predict_proba(X_test) # to predict probability\n",
    "\n",
    "target_names = ['class 0(BIKES)', 'class 1(CARS)', 'class 2(HORSES)']\n",
    "print(classification_report(np.argmax(Y_test,axis=1), y_pred,target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(Y_test,axis=1), y_pred))\n",
    "\n",
    "# saving weights\n",
    "\n",
    "fname = \"weights-Test-CNN.hdf5\"\n",
    "model.save_weights(fname,overwrite=True)\n",
    "\n",
    "\n",
    "\n",
    "# Loading weights\n",
    "\n",
    "fname = \"weights-Test-CNN.hdf5\"\n",
    "model.load_weights(fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
