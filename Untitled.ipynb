{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#KERAS\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import theano\n",
    "from PIL import Image\n",
    "from numpy import *\n",
    "# SKLEARN\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 300, 300\n",
    "\n",
    "# number of channels\n",
    "img_channels = 1\n",
    "\n",
    "path1 = '/Users/dcolton/Desktop/capstone/A/A/test/'   \n",
    "path2 = '/Users/dcolton/Desktop/capstone/A/A/gray/'  #path of folder to save images    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    }
   ],
   "source": [
    "listing = os.listdir(path1) \n",
    "num_samples=size(listing)\n",
    "print listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for file in listing:\n",
    "    im = Image.open(path1 + file)   \n",
    "    img = im.resize((img_rows,img_cols))\n",
    "    gray = img.convert('L')          \n",
    "    gray.save(path2 +  file, \"JPEG\")\n",
    "\n",
    "imlist = os.listdir(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for file in listing:\n",
    "    im = Image.open(path1 + '\\\\' + file)   \n",
    "    img = im.resize((img_rows,img_cols))\n",
    "    gray = img.convert('L')          \n",
    "    gray.save(path2 +'\\\\' +  file, \"JPEG\")\n",
    "\n",
    "imlist = os.listdir(path2)\n",
    "\n",
    "im1 = array(Image.open('input_data_resized' + '\\\\'+ imlist[0])) # open one image to get size\n",
    "m,n = im1.shape[0:2] # get the size of the images\n",
    "imnbr = len(imlist) # get the number of images\n",
    "\n",
    "# create matrix to store all flattened images\n",
    "immatrix = array([array(Image.open('input_data_resized'+ '\\\\' + im2)).flatten()\n",
    "              for im2 in imlist],'f')\n",
    "                \n",
    "label=np.ones((num_samples,),dtype = int)\n",
    "label[0:89]=0\n",
    "label[89:187]=1\n",
    "label[187:]=2\n",
    "\n",
    "\n",
    "data,Label = shuffle(immatrix,label, random_state=2)\n",
    "train_data = [data,Label]\n",
    "\n",
    "img=immatrix[167].reshape(img_rows,img_cols)\n",
    "plt.imshow(img)\n",
    "plt.imshow(img,cmap='gray')\n",
    "print (train_data[0].shape)\n",
    "print (train_data[1].shape)\n",
    "\n",
    "#%%\n",
    "\n",
    "#batch_size to train\n",
    "batch_size = 32\n",
    "# number of output classes\n",
    "nb_classes = 3\n",
    "# number of epochs to train\n",
    "nb_epoch = 20\n",
    "\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "\n",
    "#%%\n",
    "(X, y) = (train_data[0],train_data[1])\n",
    "\n",
    "\n",
    "# STEP 1: split X and y into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "i = 100\n",
    "plt.imshow(X_train[i, 0], interpolation='nearest')\n",
    "print(\"label : \", Y_train[i,:])\n",
    "\n",
    "#%%\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                        border_mode='valid',\n",
    "                        input_shape=(1, img_rows, img_cols)))\n",
    "convout1 = Activation('relu')\n",
    "model.add(convout1)\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
    "convout2 = Activation('relu')\n",
    "model.add(convout2)\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
    "\n",
    "#%%\n",
    "\n",
    "hist = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "              show_accuracy=True, verbose=1, validation_data=(X_test, Y_test))\n",
    "            \n",
    "            \n",
    "hist = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "              show_accuracy=True, verbose=1, validation_split=0.2)\n",
    "\n",
    "\n",
    "# visualizing losses and accuracy\n",
    "\n",
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['acc']\n",
    "val_acc=hist.history['val_acc']\n",
    "xc=range(nb_epoch)\n",
    "\n",
    "plt.figure(1,figsize=(7,5))\n",
    "plt.plot(xc,train_loss)\n",
    "plt.plot(xc,val_loss)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('train_loss vs val_loss')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'])\n",
    "print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n",
    "\n",
    "plt.figure(2,figsize=(7,5))\n",
    "plt.plot(xc,train_acc)\n",
    "plt.plot(xc,val_acc)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('train_acc vs val_acc')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'],loc=4)\n",
    "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#%%       \n",
    "\n",
    "score = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(model.predict_classes(X_test[1:5]))\n",
    "print(Y_test[1:5])\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "# visualizing intermediate layers\n",
    "\n",
    "output_layer = model.layers[1].get_output()\n",
    "output_fn = theano.function([model.layers[0].get_input()], output_layer)\n",
    "\n",
    "# the input image\n",
    "\n",
    "input_image=X_train[0:1,:,:,:]\n",
    "print(input_image.shape)\n",
    "\n",
    "plt.imshow(input_image[0,0,:,:],cmap ='gray')\n",
    "plt.imshow(input_image[0,0,:,:])\n",
    "\n",
    "\n",
    "output_image = output_fn(input_image)\n",
    "print(output_image.shape)\n",
    "\n",
    "# Rearrange dimension so we can plot the result \n",
    "output_image = np.rollaxis(np.rollaxis(output_image, 3, 1), 3, 1)\n",
    "print(output_image.shape)\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(8,8))\n",
    "for i in range(32):\n",
    "    ax = fig.add_subplot(6, 6, i+1)\n",
    "    #ax.imshow(output_image[0,:,:,i],interpolation='nearest' ) #to see the first filter\n",
    "    ax.imshow(output_image[0,:,:,i],cmap=matplotlib.cm.gray)\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "    plt.tight_layout()\n",
    "plt\n",
    "\n",
    "# Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print(y_pred)\n",
    "  \n",
    "                       (or)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "p=model.predict_proba(X_test) # to predict probability\n",
    "\n",
    "target_names = ['class 0(BIKES)', 'class 1(CARS)', 'class 2(HORSES)']\n",
    "print(classification_report(np.argmax(Y_test,axis=1), y_pred,target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(Y_test,axis=1), y_pred))\n",
    "\n",
    "# saving weights\n",
    "\n",
    "fname = \"weights-Test-CNN.hdf5\"\n",
    "model.save_weights(fname,overwrite=True)\n",
    "\n",
    "\n",
    "\n",
    "# Loading weights\n",
    "\n",
    "fname = \"weights-Test-CNN.hdf5\"\n",
    "model.load_weights(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
